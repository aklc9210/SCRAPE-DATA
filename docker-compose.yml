crawling_worker:
  build: ./SCRAPE-DATA     # thư mục chứa mã nguồn SCRAPE-DATA (hoặc image docker nếu đã có)
  container_name: crawling_worker
  env_file: .env           # dùng chung cấu hình môi trường (RabbitMQ URL, MongoDB URL, etc.)
  command: celery -A tasks worker --loglevel=info
  depends_on:
    - rabbitmq
    - mongodb

crawling_scheduler:
  build: ./SCRAPE-DATA
  container_name: crawling_scheduler
  env_file: .env
  command: celery -A tasks beat --loglevel=info
  depends_on:
    - rabbitmq
