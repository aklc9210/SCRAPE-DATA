# #!/usr/bin/env python3
# # test_all_categories.py

# import asyncio
# from crawler.bhx.fetch_data import BHXDataFetcher, db
# from crawler.bhx.fetch_store_by_province import fetch_stores_async

# async def main():
#     # 1) Kh·ªüi t·∫°o fetcher v√† intercept token
#     fetcher = BHXDataFetcher()
#     await fetcher.init_token()

#     # 2) L·∫•y danh s√°ch stores ·ªü TP. HCM (province_id = 3)
#     province_id = 3
#     district_id = 2087
#     ward_id = 27127
#     stores = await fetch_stores_async(
#         province_id=province_id,
#         token=fetcher.token,
#         deviceid=fetcher.deviceid,
#         district_id=district_id,
#         ward_id=ward_id,
#         page_size=100
#     )

#     if not stores:
#         print("‚ùå Kh√¥ng t√¨m th·∫•y c·ª≠a h√†ng n√†o ·ªü TP.HCM")
#         await fetcher.close()
#         return

#     # 3) Ch·ªçn c·ª≠a h√†ng ƒë·∫ßu ti√™n ƒë·ªÉ test
#     store = stores[0]
#     store_id   = store["storeId"]
#     ward_id    = store["wardId"]
#     district_id = store["districtId"]
#     print(f"üîé Test crawl c·ª≠a h√†ng: {store.get('storeLocation')} (ID: {store_id})\n")

#     # 4) ƒê·ªçc t·∫•t c·∫£ category t·ª´ MongoDB
#     categories = list(db.categories.find({}))
#     if not categories:
#         print("‚ùå Ch∆∞a c√≥ category n√†o trong DB.")
#         await fetcher.close()
#         return

#     total_products = 0

#     # 5) Loop qua t·ª´ng category
#     for cat_doc in categories:
#         cat_name = cat_doc["name"]
#         links    = cat_doc.get("links", [])
#         if not links:
#             continue

#         print(f"=== Category: {cat_name} ({len(links)} link) ===")
#         for url in links:
#             print(f" ‚Üí Crawling: https://www.bachhoaxanh.com/{url}")
#             products = await fetcher.fetch_product_info(
#                 province_id=province_id,
#                 ward_id=ward_id,
#                 district_id=district_id,
#                 store_id=store_id,
#                 category_url=url,
#                 isMobile=True,
#                 page_size=10
#             )
#             count = len(products)
#             total_products += count
#             print(f"   ‚úì L·∫•y ƒë∆∞·ª£c {count} s·∫£n ph·∫©m t·ª´ link n√†y.\n")

#     print(f"üåü T·ªïng c·ªông ƒë√£ crawl {total_products} products cho c·ª≠a h√†ng {store_id}.\n")

#     # 6) ƒê√≥ng fetcher
#     await fetcher.close()

# if __name__ == "__main__":
#     asyncio.run(main())
